<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rTales: DataScience in Short</title>
    <link>/</link>
    <description>Recent content on rTales: DataScience in Short</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-EN</language>
    <managingEditor>alvaroaguado3@gmail.com (Alvaro Aguado)</managingEditor>
    <webMaster>alvaroaguado3@gmail.com (Alvaro Aguado)</webMaster>
    <copyright>(c) 2020 Alvaro Aguado</copyright>
    <lastBuildDate>Sun, 22 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How to fit sigmoid to time series data</title>
      <link>/how-to-fit-sigmoid-to-time-series-data/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/how-to-fit-sigmoid-to-time-series-data/</guid>
      <description>Question:How can I fit a sigmoid function to time series data in R?
Solution:To fit a non linear regression with a sigmoid function to time series data you can use the nls function with a self-start function. In this case SSlogis
require(tidyverse)## Loading required package: tidyverse## -- Attaching packages -------------------------- tidyverse 1.2.1 --## v ggplot2 3.2.1 v purrr 0.3.3## v tibble 2.1.3 v dplyr 0.</description>
    </item>
    
    <item>
      <title>Tutorial:How does certainty of beta estimation changes with sample size?</title>
      <link>/how-does-certainty-of-beta-estimation-changes-with-sample-size/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/how-does-certainty-of-beta-estimation-changes-with-sample-size/</guid>
      <description>Linear RegressionWe first simulate data to see how to see how to calculate beta (slope) and alpha (constant) coefficients. We use a sampling method from a multivariate normal distribution with mean [0,0] and some covariance between independent variable x and target variable y.
# Import Libraries import numpy as npimport matplotlib.pyplot as pltm = range(0,10000) # Datasetsn = 100 # number of pointssigx = .</description>
    </item>
    
    <item>
      <title>Tutorial:Regression from Scratch and Simple</title>
      <link>/regression-from-scratch-and-simple/</link>
      <pubDate>Sun, 09 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/regression-from-scratch-and-simple/</guid>
      <description>Question:I’m not a math expert. But I want to understand least squares completely. Can you please explain how to do Least Squares Regression from Scratch?
PrefaceRegression is at the core of Machine Learning. Almost all the literature in predictive modelling, time series forecasting, and Artificial Intelligence, relies on the basic principles of linear regression. Nowadays everyone can compute linear regression using statistical software or even Excel, but how many people really know what’s going on behind the scenes.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part I</title>
      <link>/forcing-regression-coefficients-in-r-part-i/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-i/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with nls
The function lm does not provide a way to restrict coefficients. Instead we can use the function nls under the algorithm port.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part II Lasso</title>
      <link>/forcing-regression-coefficients-in-r-part-ii-lasso/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-ii-lasso/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with Lasso using glmnet
In this case glmnet provides a convenient way to restrict coefficients regularizing the coefficients.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part III Bayesian</title>
      <link>/forcing-regression-coefficients-in-r-part-iii-bayesian/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-iii-bayesian/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with bayes regresison with the brms package
In this case bayes provides a convenient way to restrict coefficients regularizing the coefficients.</description>
    </item>
    
    <item>
      <title>Here I will keep some resources like dynamic turorials done in R or Python</title>
      <link>/resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/resources/</guid>
      <description>Question: How do I calculate Type I, Type II and Power in a statistical hypothesis testing?Type I &amp;amp; Type II Error and Power</description>
    </item>
    
    <item>
      <title>What is rTales? Who did this?</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/about/</guid>
      <description>After some research about setting up a Blogdown site, conceptualization of ideas and also some inevitable procrastination, finally rTales has come to fruition.
What is rTales?rTales is (yet another) Data Science blog, but cutting the fluff. The idea is to answer practical data science questions first with a Reprex. This term stands for ‘Reproducible example’ and it was coined by Romain Francois.
New favorite word smash: reprex, for {rep}roducible {ex}ample.</description>
    </item>
    
  </channel>
</rss>