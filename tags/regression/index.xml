<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Regression on rTales: DataScience in Short</title>
    <link>/tags/regression/</link>
    <description>Recent content in Regression on rTales: DataScience in Short</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-EN</language>
    <managingEditor>alvaroaguado3@gmail.com (Alvaro Aguado)</managingEditor>
    <webMaster>alvaroaguado3@gmail.com (Alvaro Aguado)</webMaster>
    <copyright>(c) 2020 Alvaro Aguado</copyright>
    <lastBuildDate>Sun, 09 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tutorial:Regression from Scratch and Simple</title>
      <link>/regression-from-scratch-and-simple/</link>
      <pubDate>Sun, 09 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/regression-from-scratch-and-simple/</guid>
      <description>Question:I’m not a math expert. But I want to understand least squares completely. Can you please explain how to do Least Squares Regression from Scratch?
Solution:Let’s see the hard math solution first and then we will walk through to make sure we understand this fully. Revisit this once you are done to see if you get it the second time.
Imagine we have the output variable \(y = \begin{pmatrix} 2 \\ 1 \end{pmatrix}\) and the input variables \(X = \begin{pmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; 2 \end{pmatrix}\) where the first column represents the intercept and the second column is the second variable.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part I</title>
      <link>/forcing-regression-coefficients-in-r-part-i/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-i/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with nls
The function lm does not provide a way to restrict coefficients. Instead we can use the function nls under the algorithm port.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part II Lasso</title>
      <link>/forcing-regression-coefficients-in-r-part-ii-lasso/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-ii-lasso/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with Lasso using glmnet
In this case glmnet provides a convenient way to restrict coefficients regularizing the coefficients.</description>
    </item>
    
    <item>
      <title>Forcing Regression Coefficients in R - Part III Bayesian</title>
      <link>/forcing-regression-coefficients-in-r-part-iii-bayesian/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <author>alvaroaguado3@gmail.com (Alvaro Aguado)</author>
      <guid>/forcing-regression-coefficients-in-r-part-iii-bayesian/</guid>
      <description>Question:I’m working on a regression model and I need to force the regression coefficients to be positive. How can I accomplish this in R?
Solution:For linear model regression model with restricted coefficients you have 3 options: Linear with nls, Bayes with brms and Lasso. Here we will look at Linear Model with bayes regresison with the brms package
In this case bayes provides a convenient way to restrict coefficients regularizing the coefficients.</description>
    </item>
    
  </channel>
</rss>